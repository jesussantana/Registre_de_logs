{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT Academy - Data Science amb Python\n",
    "## Tasca 7: Estructura de control\n",
    "\n",
    "###  [Github Registre de Logs](https://github.com/jesussantana/Registre_de_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 1\n",
    "- Normalitza, identifica i enumera cada un dels atributs / variables de l'estructura de l'arxiu \"Web_access_log-akumenius.com\" que trobaràs al repositori de GitHub \"Data-sources\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import collections, numpy\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Web_access_log-akumenius.com.txt'\n",
    "\n",
    "Logs_raw = pd.read_csv(path, sep='\\s | \\- | \\\"', names =['DNS','IP','Location','Date','Time','Request','Status','Size','Referer','UserAgent'], engine='python')\n",
    "\n",
    "Logs_copy = Logs_raw.copy()\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 2\n",
    "- Neteja, preprocesa, estructura i transforma (dataframe) les dades del registre d'Accés a la web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reorder columns of data\n",
    "\n",
    "Logs_copy.UserAgent = Logs_copy.Time\n",
    "Logs_copy.Request = Logs_copy.Location\n",
    "Logs_copy.Referer = Logs_copy.Date\n",
    "Logs_copy.Date = Logs_copy.IP\n",
    "Logs_copy.Time = Logs_copy.IP = Logs_copy.Location = np.nan\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNS & IP data split\n",
    "\n",
    "Logs_copy[['DNS','IP']] = Logs_copy.DNS.str.split('\\s', expand = True).get([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.DNS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Logs_copy.IP.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time data extraction\n",
    "\n",
    "Logs_copy.Time = Logs_copy.Date.str.extract(':(\\d{2}:\\d{2}:\\d{2}.*)]')\n",
    "\n",
    "#Logs_copy.Time = pd.to_datetime(Logs_copy.Time, format = '%H:%M:%S %z')\n",
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date data extraction\n",
    "\n",
    "Logs_copy.Date = Logs_copy.Date.str.extract('(\\d+/\\w+/\\d+)')\n",
    "\n",
    "#Logs_copy.Date = pd.to_datetime(Logs_copy.Date, format = '%d/%b/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request & Status data split\n",
    "\n",
    "Logs_copy[['Request','Status']] = Logs_copy.Request.str.split('\\\"', expand = True).get([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size data extraction\n",
    "\n",
    "Logs_copy.Size = Logs_copy.Status.str.extract('(\\d+$)')\n",
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Size data\n",
    "start = time.monotonic()\n",
    "\n",
    "sizes = []\n",
    "\n",
    "for index, row in Logs_copy.iterrows(): \n",
    "    \n",
    "    #if re.search('200', row.Size):\n",
    "    if row.Size == '200':\n",
    "        sizes.append(np.nan)\n",
    "    else:\n",
    "        sizes.append(row.Size)\n",
    "\n",
    "Logs_copy.Size = sizes\n",
    "\n",
    "end = time.monotonic()\n",
    "\n",
    "print(timedelta(seconds = end - start))\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Status data extraction\n",
    "\n",
    "Logs_copy.Status = Logs_copy.Status.str.extract('(\\d{3})')\n",
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Referer data\n",
    "\n",
    "start = time.monotonic()\n",
    "\n",
    "referers = []\n",
    "\n",
    "for index, row in Logs_copy.iterrows(): \n",
    "    \n",
    "    if re.search('-\"', row.Referer):\n",
    "        referers.append(np.nan)\n",
    "    else:\n",
    "        referers.append(row.Referer.rstrip(row.Referer[-1]))\n",
    "\n",
    "    \n",
    "\n",
    "Logs_copy.Referer = referers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 3\n",
    "- Geolocalitza les IP's. Aqui tens una pagina de interes:\n",
    "  - [IP2Locattion](https://blog.ip2location.com/knowledge-base/how-to-add-a-sub-account-in-ip2location/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ips_export= Logs_copy.IP.copy()\n",
    "\n",
    "Ips_export.replace('', 'null', inplace = True)\n",
    "\n",
    "Ips_export.to_csv('../Data/Ips_export.csv', index = False)"
   ]
  },
  {
   "source": [
    "- Extracion de Localizaciones \n",
    "  - [Extract_Locattion](https://github.com/jesussantana/Registre_de_logs/Tasca_7_Registre_de_Logs_Ips_Exercici3.ypynb)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import json\n",
    "from ip2geotools.databases.noncommercial import DbIpCity'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Ips\n",
    "\n",
    "'''ips = Logs_copy.IP.unique()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extract Locations\n",
    "\n",
    "'''localhost = \"127.0.0.1\"\n",
    "\n",
    "def extract_location(ip):\n",
    "    \n",
    "    try:\n",
    "        if ip == localhost:\n",
    "            return ('Local', 'Local')\n",
    "\n",
    "        else:\n",
    "            response = DbIpCity.get(ip, api_key = 'free').to_json()    \n",
    "            data = json.loads(response)\n",
    "            return data['city'], data['country']\n",
    "    \n",
    "    except:\n",
    "        return np.nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of locations for unique Ips\n",
    "\n",
    "'''start = time.monotonic()\n",
    "\n",
    "locations = []\n",
    "\n",
    "for item in ips:\n",
    "    \n",
    "    locations.append(extract_location(item))  \n",
    "\n",
    "end = time.monotonic()\n",
    "\n",
    "print(timedelta(seconds = end - start))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Location Test\n",
    "\n",
    "'''extract_location(Logs_copy.IP[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare ips & add location\n",
    "\n",
    "'''start = time.monotonic()\n",
    "\n",
    "IP_locations = []\n",
    "\n",
    "for index, row in Logs_copy.iterrows():\n",
    "    \n",
    "    # iterate the two lists\n",
    "    for a, b in zip(ips, locations):\n",
    "        \n",
    "        # Compare & add\n",
    "        if row.IP == a:\n",
    "            IP_locations.append(b)  \n",
    "\n",
    "end = time.monotonic()\n",
    "\n",
    "print(timedelta(seconds = end - start))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Logs_copy.Location = IP_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Locations_export.csv'\n",
    "\n",
    "Locations_raw = pd.read_csv(path, sep='delimiter', names =['IP','Location'], engine='python')\n",
    "\n",
    "Locations_copy = Locations_raw.copy()\n",
    "\n",
    "Locations_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Locations_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.Location = Locations_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 4\n",
    "- Mostreu-me la teva creativitat, Sorprèn-me fes un pas més enllà amb el analysis anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract UserAgent Data\n",
    "\n",
    "from device_detector import SoftwareDetector\n",
    "\n",
    "Devices = Logs_copy.UserAgent\n",
    "device = []\n",
    "\n",
    "for x in Devices:\n",
    "    \n",
    "    device.append(SoftwareDetector(x).parse())\n",
    "\n",
    "client_name = []\n",
    "client_type = []\n",
    "client_version = []\n",
    "os_name = []\n",
    "os_version = []\n",
    "device_type = []\n",
    "\n",
    "for x in device:\n",
    "    \n",
    "    client_name.append(x.client_name())\n",
    "    client_type.append(x.client_type())\n",
    "    client_version.append(x.client_version())\n",
    "    os_name.append(x.os_name())\n",
    "    os_version.append(x.os_version())\n",
    "    device_type.append(x.device_type())\n",
    "\n",
    "Logs_copy['Client_Name'] = client_name\n",
    "Logs_copy['Client_Type'] = client_type\n",
    "Logs_copy['Client_Version'] = client_version\n",
    "Logs_copy['Os_Name'] = os_name\n",
    "Logs_copy['Os_Version'] = os_version\n",
    "Logs_copy['Device_Type'] = device_type\n",
    "\n",
    "Logs_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.UserAgent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(Logs_copy['UserAgent'])\n",
    "\n",
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Client Data\n",
    "client = []\n",
    "\n",
    "for index, row in Logs_copy.iterrows(): \n",
    "    \n",
    "    if re.search('Apache', row.Client_Name):\n",
    "        client.append(row.Client_Name[0:6])\n",
    "    else:\n",
    "        client.append(row.Client_Name)\n",
    "\n",
    "Logs_copy.Client_Name = client\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Logs_copy.Location.value_counts(ascending = True).plot(kind = 'barh', figsize = (10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy[['DNS', 'Location']].groupby(['DNS']).count().sort_values(by = 'Location',ascending = False)\n",
    "graph = graph.rename(columns = {'Location' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'g', ylabel = 'Frequency', legend = None, figsize = (10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy[['Status', 'Time']].groupby(['Status']).count().sort_values(by = 'Time',ascending = False)\n",
    "graph = graph.rename(columns = {'Time' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'r', ylabel = 'Frequency', legend = None, figsize = (10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy[['Client_Type', 'Time']].groupby(['Client_Type']).count().sort_values(by = 'Time',ascending = False)\n",
    "graph = graph.rename(columns = {'Time' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'y', ylabel = 'Frequency', legend = None, figsize = (10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = Logs_copy, x = \"Os_Name\", hue = \"Date\", multiple = \"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = Logs_copy, x = \"Device_Type\", hue = \"Date\", multiple = \"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_export = Logs_copy.copy()\n",
    "\n",
    "Logs_export.replace('', 'null', inplace = True)\n",
    "\n",
    "Logs_export.to_csv('../Data/Logs_export.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}