{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT Academy - Data Science amb Python\n",
    "## Tasca 7: Estructura de control\n",
    "\n",
    "###  [Github Registre de Logs](https://github.com/jesussantana/Registre_de_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 1\n",
    "- Normalitza, identifica i enumera cada un dels atributs / variables de l'estructura de l'arxiu \"Web_access_log-akumenius.com\" que trobaràs al repositori de GitHub \"Data-sources\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import requests\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import io \n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from joblib import Parallel, delayed\n",
    "from pandas import json_normalize\n",
    "from shapely.geometry import Point, Polygon\n",
    "#from data_cleaner import DataCleaner\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "source": [
    "- We load the data to check how it has been distributed\n",
    "  - The variables that we will use:\n",
    "    - 'DNS','IP','Date','Time','Request','Status','Size','Referer','UserAgent'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Web_access_log-akumenius.com.txt'\n",
    "\n",
    "Logs_raw = pd.read_csv(path, sep='\\s | \\- | \\\"', names =['DNS','ip','Date','Time','Request','Status','Size','Referer','UserAgent'], engine='python')\n",
    "\n",
    "Logs_copy = Logs_raw.copy()\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 2\n",
    "- Neteja, preprocesa, estructura i transforma (dataframe) les dades del registre d'Accés a la web."
   ]
  },
  {
   "source": [
    "- Check rows and columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.shape"
   ]
  },
  {
   "source": [
    "- Check for null data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "source": [
    "- Reorder columns of data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Logs_copy.UserAgent = Logs_copy.Request\n",
    "Logs_copy.Request = Logs_copy.Date\n",
    "Logs_copy.Referer = Logs_copy.Time\n",
    "Logs_copy.Date = Logs_copy.ip\n",
    "Logs_copy.Time = Logs_copy.ip = np.nan\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- DNS & IP data split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy[['DNS','ip']] = Logs_copy.DNS.str.split('\\s', expand = True).get([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- Check how many different Ips exist"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.DNS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Logs_copy.ip.unique())"
   ]
  },
  {
   "source": [
    "- Time data extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.Time = Logs_copy.Date.str.extract(':(\\d{2}:\\d{2}:\\d{2}.*)]')\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- Date data extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.Date = Logs_copy.Date.str.extract('(\\d+/\\w+/\\d+)')\n",
    "\n",
    "Logs_copy.Date = pd.to_datetime(Logs_copy.Date, format = '%d/%b/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- Request & Status data split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy[['Request','Status']] = Logs_copy.Request.str.split('\\\"', expand = True).get([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- Size data extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.Size = Logs_copy.Status.str.extract('(\\d+$)')\n",
    "Logs_copy"
   ]
  },
  {
   "source": [
    "- Clean Size data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Logs_copy.Size = Logs_copy.Size.apply(lambda x: (np.nan if x == '200' else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "source": [
    "- Status data extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Logs_copy.Status = Logs_copy.Status.str.extract('(\\d{3})')\n",
    "Logs_copy.tail()"
   ]
  },
  {
   "source": [
    "- Clean Referer data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Logs_copy.Referer = Logs_copy.Referer.apply(lambda x: (np.nan if re.search('-\"', x) else x.rstrip(x[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 3\n",
    "- Geolocalitza les IP's. Aqui tens una pagina de interes:\n",
    "  - [freegeoip](https://freegeoip.app/)"
   ]
  },
  {
   "source": [
    "- We export Ips file for security"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ips_export= Logs_copy.ip.copy()\n",
    "\n",
    "Ips_export.replace('', 'null', inplace = True)\n",
    "\n",
    "Ips_export.to_csv('../Data/Ips_export.csv', index = False)"
   ]
  },
  {
   "source": [
    "- Ips file recovery"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Ips_export.csv'\n",
    "\n",
    "Ips_raw = pd.read_csv(path, sep= 'delimiter', engine='python')\n",
    "\n",
    "Ips_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ips_raw.tail()"
   ]
  },
  {
   "source": [
    "- Make a copy of the data to be used and we check them"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_unique = pd.DataFrame({\"ip\": Ips_raw.ip.unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ips_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_unique"
   ]
  },
  {
   "source": [
    "- Function for extract Information freegeoip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''localhost = \"127.0.0.1\"\n",
    "geolocation = []\n",
    "url = \"https://freegeoip.app/json/\"\n",
    "headers = {\n",
    "    'accept': \"application/json\",\n",
    "    'content-type': \"application/json\"\n",
    "    }\n",
    "\n",
    "def extract_info(ip):\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\"GET\", url + ip)\n",
    "        return geolocation.append(eval(response.text))\n",
    "\n",
    "    except:\n",
    "        return np.nan'''"
   ]
  },
  {
   "source": [
    "- Ips Information Extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%%time\n",
    "\n",
    "geolocation = Parallel(n_jobs = 8, backend = \"multiprocessing\")(map(delayed(extract_info), ips_unique.ip))'''"
   ]
  },
  {
   "source": [
    "- joblib.Parallel uses the backend module to start worker processes, executing tasks simultaneously on separate CPUs.\n",
    "- Less than 50 seconds for obtaining the IPS 2921 extraction, too much faster, when using 4 cores and 8 threads"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "localhost = \"127.0.0.1\"\n",
    "url = \"https://freegeoip.app/json/\"\n",
    "\n",
    "geolocation = []\n",
    "\n",
    "for ip in ips_unique.ip:\n",
    "    try:\n",
    "        response = requests.request(\"GET\", url + ip)\n",
    "        geolocation.append(eval(response.text))\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df = pd.DataFrame.from_dict(geolocation)"
   ]
  },
  {
   "source": [
    "- check the data obtained"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df"
   ]
  },
  {
   "source": [
    "Export Geolocations File"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df_export = geolocation_df.copy()\n",
    "\n",
    "geolocation_df_export.replace('', 'null', inplace = True)\n",
    "\n",
    "geolocation_df_export.to_csv('geolocation_df_export.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'geolocation_df_export.csv'\n",
    "\n",
    "geolocation_df = pd.read_csv(path, sep= ',', engine='python')\n",
    "\n",
    "geolocation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df.info()"
   ]
  },
  {
   "source": [
    "- Do a merge by the column of IPs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy2 = Logs_copy.merge(geolocation_df, on='ip', how='outer')"
   ]
  },
  {
   "source": [
    "- Check the result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy2.metro_code.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 4\n",
    "- Mostreu-me la teva creativitat, Sorprèn-me fes un pas més enllà amb el analysis anterior."
   ]
  },
  {
   "source": [
    "In progress ..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Extract UserAgent Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from device_detector import SoftwareDetector\n",
    "\n",
    "Devices = Logs_copy2.UserAgent\n",
    "\n",
    "device = Devices.apply(lambda x: SoftwareDetector(x).parse())\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "source": [
    "- Assign the values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Logs_copy2['Client_Name'] = device.apply(lambda x: x.client_name())\n",
    "Logs_copy2['Client_Type'] = device.apply(lambda x: x.client_type())\n",
    "Logs_copy2['Client_Version'] = device.apply(lambda x: x.client_version())\n",
    "Logs_copy2['Os_Name'] = device.apply(lambda x: x.os_name())\n",
    "Logs_copy2['Os_Version'] = device.apply(lambda x: x.os_version())\n",
    "Logs_copy2['Engine'] = device.apply(lambda x: x.engine())\n",
    "Logs_copy2['Device_Brand_Name'] = device.apply(lambda x: x.device_brand_name())\n",
    "Logs_copy2['Device_Model'] = device.apply(lambda x: x.device_model())\n",
    "Logs_copy2['Device_Type'] = device.apply(lambda x: x.device_type())\n",
    "\n"
   ]
  },
  {
   "source": [
    "- Rename & Reorder columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy2.columns = map(str.upper, Logs_copy2.columns)\n",
    "Logs_copy2.columns"
   ]
  },
  {
   "source": [
    "- Check the result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy2.USERAGENT[0]"
   ]
  },
  {
   "source": [
    "- The column from which we have extracted the data is deleted"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(Logs_copy2['USERAGENT'])\n",
    "\n",
    "Logs_copy2.tail()"
   ]
  },
  {
   "source": [
    "- Clean Client Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Logs_copy2.CLIENT_NAME = Logs_copy2.CLIENT_NAME.apply(lambda x: (x[0:6] if re.search('Apache', x) else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy2"
   ]
  },
  {
   "source": [
    "- Visualize the data in progress"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Logs_copy2.COUNTRY_NAME.value_counts(normalize=False).where(Logs_copy2.COUNTRY_NAME.value_counts() > 2000).plot(kind = 'pie', figsize = (14,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy2[['DNS', 'CITY']].groupby(['DNS']).count().sort_values(by = 'CITY',ascending = False)\n",
    "graph = graph.rename(columns = {'CITY' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'b', ylabel = 'Frequency', legend = None, figsize = (14,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "sns.displot(data = Logs_copy2, x = \"DEVICE_TYPE\", hue = \"OS_NAME\", multiple = \"stack\", ax= ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times['weekday'] = Logs_copy2['time'].dt.weekday.map({0 : 'Sunday', 1 : 'Monday', 2 : 'Tuesday', 3 : 'Wednesday', 4 : 'Thursday', 5 : 'Friday', 6 : 'Saturday'})\n",
    "times['month'] = Logs_copy2['time'].dt.month\n",
    "times['monthday'] = Logs_copy2['time'].dt.day\n",
    "times['yearday'] = Logs_copy2['time'].dt.dayofyear\n",
    "times['hour'] = Logs_copy2['time'].dt.hour\n",
    "\n",
    "logs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (times[['browser', 'hour', 'month']]\n",
    "     .groupby(['browser', 'hour'])\n",
    "     .count()   \n",
    "     .reset_index()\n",
    "     .rename(columns = {'month':'logs'})\n",
    "     .sort_values('logs', ascending = False)\n",
    "     .head(130)\n",
    ")\n",
    "\n",
    "ax = plt.subplots (figsize = (15,8))\n",
    "ax = sns.lineplot(data = data, x = 'hour', y = 'logs', hue = 'browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy2[['STATUS', 'DNS']].groupby(['STATUS']).count().sort_values(by = 'DNS',ascending = False)\n",
    "graph = graph.rename(columns = {'DNS' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'r', ylabel = 'Frequency', legend = None, figsize = (14,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy2[['CLIENT_TYPE', 'DNS']].groupby(['CLIENT_TYPE']).count().sort_values(by = 'DNS',ascending = False)\n",
    "graph = graph.rename(columns = {'DNS' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'g', ylabel = 'Frequency', legend = None, figsize = (14,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "sns.displot(data = Logs_copy2, x = \"DEVICE_TYPE\", hue = \"DNS\", multiple = \"stack\", ax= ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "sns.displot(data = Logs_copy2, x = \"OS_NAME\", hue = \"DEVICE_MODEL\", multiple = \"stack\", ax= ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEOLOCATIONS = Logs_copy2[Logs_copy2['LONGITUDE'] != ' '][['IP', 'LONGITUDE', 'LATITUDE']].astype({'LONGITUDE': float, 'LATITUDE': float})\n",
    "GEOLOCATIONS = (GEOLOCATIONS[['IP', 'LONGITUDE', 'LATITUDE']].groupby('IP')\n",
    "              .agg({'LONGITUDE' : np.mean, 'LATITUDE': np.mean, 'IP' : 'count'})\n",
    "              .astype({'IP': float})\n",
    "                       \n",
    "            )\n",
    "logs_byIP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots (figsize = (15,8))\n",
    "\n",
    "plt.scatter(x = GEOLOCATIONS['LONGITUDE'],\n",
    "            y = GEOLOCATIONS['LATITUDE'],\n",
    "            s = GEOLOCATIONS['IP']*2/10,\n",
    "            alpha = 0.16,\n",
    "            c = 'darkgreen')\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.boundary.plot(ax = ax, figsize=(20,5), linewidth=0.25, edgecolor='black', color='black')\n",
    "\n",
    "plt.ylim((-60,70))\n",
    "plt.xlim((-130,150))\n",
    "\n",
    "plt.title('Geolocations of web visits')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots (figsize = (15,8))\n",
    "\n",
    "plt.scatter(x = GEOLOCATIONS['LONGITUDE'],\n",
    "            y = GEOLOCATIONS['LATITUDE'],\n",
    "            s = GEOLOCATIONS['IP']*2/10,\n",
    "           alpha = 0.16,\n",
    "           c = 'darkgreen')\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.boundary.plot(ax = ax, figsize=(20,5), linewidth=0.25, edgecolor='black', color='black')\n",
    "\n",
    "plt.ylim((25,60))\n",
    "plt.xlim((-20,30))\n",
    "\n",
    "plt.title('Zoom zone more density of visits to the web')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "- Save the data obtained for later reuse"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_export = Logs_copy2.copy()\n",
    "\n",
    "Logs_export.replace('', 'null', inplace = True)\n",
    "\n",
    "Logs_export.to_csv('../Data/Logs_export.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}