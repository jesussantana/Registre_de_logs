{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT Academy - Data Science amb Python\n",
    "## Tasca 7: Estructura de control\n",
    "\n",
    "###  [Github Registre de Logs](https://github.com/jesussantana/Registre_de_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 1\n",
    "- Normalitza, identifica i enumera cada un dels atributs / variables de l'estructura de l'arxiu \"Web_access_log-akumenius.com\" que trobaràs al repositori de GitHub \"Data-sources\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import io \n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from joblib import Parallel, delayed\n",
    "from pandas import json_normalize\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "source": [
    "- We load the data to check how it has been distributed\n",
    "  - The variables that we will use:\n",
    "    - 'DNS','IP','Date','Time','Request','Status','Size','Referer','UserAgent'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Web_access_log-akumenius.com.txt'\n",
    "\n",
    "Logs_raw = pd.read_csv(path, sep='\\s | \\- | \\\"', names =['DNS','ip','Date','Time','Request','Status','Size','Referer','UserAgent'], engine='python')\n",
    "\n",
    "Logs_copy = Logs_raw.copy()\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 2\n",
    "- Neteja, preprocesa, estructura i transforma (dataframe) les dades del registre d'Accés a la web."
   ]
  },
  {
   "source": [
    "- Check rows and columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.shape"
   ]
  },
  {
   "source": [
    "- Check for null data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "source": [
    "- Reorder columns of data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Logs_copy.UserAgent = Logs_copy.Request\n",
    "Logs_copy.Request = Logs_copy.Date\n",
    "Logs_copy.Referer = Logs_copy.Time\n",
    "Logs_copy.Date = Logs_copy.ip\n",
    "Logs_copy.Time = Logs_copy.ip = np.nan\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- DNS & IP data split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy[['DNS','ip']] = Logs_copy.DNS.str.split('\\s', expand = True).get([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- Check how many different Ips exist"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.DNS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Logs_copy.ip.unique())"
   ]
  },
  {
   "source": [
    "- Time data extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.Time = Logs_copy.Date.str.extract(':(\\d{2}:\\d{2}:\\d{2}.*)]')\n",
    "\n",
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- Date data extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.Date = Logs_copy.Date.str.extract('(\\d+/\\w+/\\d+)')\n",
    "\n",
    "Logs_copy.Date = pd.to_datetime(Logs_copy.Date, format = '%d/%b/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- Request & Status data split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy[['Request','Status']] = Logs_copy.Request.str.split('\\\"', expand = True).get([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.head()"
   ]
  },
  {
   "source": [
    "- Size data extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.Size = Logs_copy.Status.str.extract('(\\d+$)')\n",
    "Logs_copy"
   ]
  },
  {
   "source": [
    "- Clean Size data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Logs_copy.Size = Logs_copy.Size.apply(lambda x: (np.nan if x == '200' else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "source": [
    "- Status data extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Logs_copy.Status = Logs_copy.Status.str.extract('(\\d{3})')\n",
    "Logs_copy.tail()"
   ]
  },
  {
   "source": [
    "- Clean Referer data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Logs_copy.Referer = Logs_copy.Referer.apply(lambda x: (np.nan if re.search('-\"', x) else x.rstrip(x[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 3\n",
    "- Geolocalitza les IP's. Aqui tens una pagina de interes:\n",
    "  - [freegeoip](https://freegeoip.app/)"
   ]
  },
  {
   "source": [
    "- We export Ips file for security"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ips_export= Logs_copy.ip.copy()\n",
    "\n",
    "Ips_export.replace('', 'null', inplace = True)\n",
    "\n",
    "Ips_export.to_csv('../Data/Ips_export.csv', index = False)"
   ]
  },
  {
   "source": [
    "- Ips file recovery"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Ips_export.csv'\n",
    "\n",
    "Ips_raw = pd.read_csv(path, sep= 'delimiter', engine='python')\n",
    "\n",
    "Ips_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ips_raw.tail()"
   ]
  },
  {
   "source": [
    "- Make a copy of the data to be used and we check them"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ips_copy = Ips_raw.copy()\n",
    "ips_unique = Ips_copy.ip.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Ips_copy.ip.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_unique"
   ]
  },
  {
   "source": [
    "- Function for extract Information freegeoip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "localhost = \"127.0.0.1\"\n",
    "\n",
    "Info_list = []\n",
    "\n",
    "def extract_info(ip):\n",
    "\n",
    "    try:\n",
    "        response = urlopen(\"https://freegeoip.app/json/\" + ip)\n",
    "        return json.load(response)\n",
    "\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "source": [
    "- Ips Information Extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_info(ips_unique[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geolocation = Parallel(n_jobs = 8, backend = \"multiprocessing\")(map(delayed(extract_info), ips_unique))"
   ]
  },
  {
   "source": [
    "- joblib.Parallel uses the backend module to start worker processes, executing tasks simultaneously on separate CPUs.\n",
    "- Less than 50 seconds for obtaining the IPS 2921 extraction, too much faster, when using 4 cores and 8 threads"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(geolocation_list)"
   ]
  },
  {
   "source": [
    "- check the data obtained"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_list[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geolocation_list)"
   ]
  },
  {
   "source": [
    "Function for File to json"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('geolocation.json', 'w') as file:\n",
    "    json.dump(geolocation_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_list = json.loads(open('geolocation.json').read())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df = pd.DataFrame.from_dict([geolocation_list], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df = pd.DataFrame.from_list(geolocation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "geolocation_df = []  \n",
    "for x in range(0, len(geolocation_list)-1):\n",
    "    geolocation_df.append(geolocation_list[x])\n",
    "\n",
    "geolocation_df[1]['country_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(geolocation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_list[1]['ip']"
   ]
  },
  {
   "source": [
    "- Create variable to join the data obtained with the ones we had"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_list[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_df = geolocation_list.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geolocation)"
   ]
  },
  {
   "source": [
    "- Do a merge by the column of IPs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy = Logs_copy.merge(geolocation, on='ip', how='inner')"
   ]
  },
  {
   "source": [
    "- Check the result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercici 4\n",
    "- Mostreu-me la teva creativitat, Sorprèn-me fes un pas més enllà amb el analysis anterior."
   ]
  },
  {
   "source": [
    "- Extract data from location information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In progress ..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Extract UserAgent Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from device_detector import SoftwareDetector\n",
    "\n",
    "Devices = Logs_copy.UserAgent\n",
    "\n",
    "device = Devices.apply(lambda x: SoftwareDetector(x).parse())\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "source": [
    "- Assign the values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Logs_copy['Client_Name'] = device.apply(lambda x: x.client_name())\n",
    "Logs_copy['Client_Type'] = device.apply(lambda x: x.client_type())\n",
    "Logs_copy['Client_Version'] = device.apply(lambda x: x.client_version())\n",
    "Logs_copy['Os_Name'] = device.apply(lambda x: x.os_name())\n",
    "Logs_copy['Os_Version'] = device.apply(lambda x: x.os_version())\n",
    "Logs_copy['Device_Type'] = device.apply(lambda x: x.device_type())"
   ]
  },
  {
   "source": [
    "- Check the result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy.UserAgent[0]"
   ]
  },
  {
   "source": [
    "- The column from which we have extracted the data is deleted"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(Logs_copy['UserAgent'])\n",
    "\n",
    "Logs_copy.tail()"
   ]
  },
  {
   "source": [
    "- Clean Client Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Logs_copy.Client_Name = Logs_copy.Client_Name.apply(lambda x: (x[0:6] if re.search('Apache', x) else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_copy"
   ]
  },
  {
   "source": [
    "- Visualize the data in progress"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Logs_copy.Location.value_counts(normalize=False).where(Logs_copy.Location.value_counts() > 2000).plot(kind = 'pie', figsize = (10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy[['DNS', 'Location']].groupby(['DNS']).count().sort_values(by = 'Location',ascending = False)\n",
    "graph = graph.rename(columns = {'Location' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'g', ylabel = 'Frequency', legend = None, figsize = (10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy[['Status', 'Time']].groupby(['Status']).count().sort_values(by = 'Time',ascending = False)\n",
    "graph = graph.rename(columns = {'Time' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'r', ylabel = 'Frequency', legend = None, figsize = (10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Logs_copy[['Client_Type', 'Time']].groupby(['Client_Type']).count().sort_values(by = 'Time',ascending = False)\n",
    "graph = graph.rename(columns = {'Time' : 'Frequency'})\n",
    "graph.plot.bar(y = 'Frequency', color = 'y', ylabel = 'Frequency', legend = None, figsize = (10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = Logs_copy, x = \"Os_Name\", hue = \"Date\", multiple = \"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(Logs_copy.Os_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = Logs_copy, x = \"Device_Type\", hue = \"Date\", multiple = \"stack\")"
   ]
  },
  {
   "source": [
    "- Save the data obtained for later reuse"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logs_export = Logs_copy.copy()\n",
    "\n",
    "Logs_export.replace('', 'null', inplace = True)\n",
    "\n",
    "Logs_export.to_csv('../Data/Logs_export.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}